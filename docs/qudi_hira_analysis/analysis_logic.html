<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>qudi_hira_analysis.analysis_logic API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>qudi_hira_analysis.analysis_logic</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from __future__ import annotations

import logging
import random
import re
from itertools import product
from typing import Tuple, TYPE_CHECKING

import numpy as np
import pandas as pd
from joblib import Parallel, delayed, cpu_count
from tqdm import tqdm

import qudi_hira_analysis._raster_odmr_fitting as rof
from qudi_hira_analysis._qudi_fit_logic import FitLogic

if TYPE_CHECKING:
    from lmfit import Model, Parameters, Parameter
    from lmfit.model import ModelResult
    from .measurement_dataclass import MeasurementDataclass

logging.basicConfig(format=&#39;%(name)s :: %(levelname)s :: %(message)s&#39;, level=logging.INFO)


class FitMethodsAndEstimators:
    &#34;&#34;&#34;
        Class for storing fit methods and estimators.
        Fit methods are stored as tuples of (method, estimator)
        where method is the name of the fit method and estimator is the name of the estimator.
    &#34;&#34;&#34;
    # Fit methods with corresponding estimators
    antibunching: tuple = (&#34;antibunching&#34;, &#34;dip&#34;)
    hyperbolicsaturation: tuple = (&#34;hyperbolicsaturation&#34;, &#34;generic&#34;)
    lorentzian: tuple = (&#34;lorentzian&#34;, &#34;dip&#34;)
    lorentziandouble: tuple = (&#34;lorentziandouble&#34;, &#34;dip&#34;)
    sineexponentialdecay: tuple = (&#34;sineexponentialdecay&#34;, &#34;generic&#34;)
    decayexponential: tuple = (&#34;decayexponential&#34;, &#34;generic&#34;)
    gaussian: tuple = (&#34;gaussian&#34;, &#34;dip&#34;)
    gaussiandouble: tuple = (&#34;gaussiandouble&#34;, &#34;dip&#34;)
    gaussianlinearoffset: tuple = (&#34;gaussianlinearoffset&#34;, &#34;dip&#34;)
    lorentziantriple: tuple = (&#34;lorentziantriple&#34;, &#34;dip&#34;)
    biexponential: tuple = (&#34;biexponential&#34;, &#34;generic&#34;)
    decayexponentialstretched: tuple = (&#34;decayexponentialstretched&#34;, &#34;generic&#34;)
    linear: tuple = (&#34;linear&#34;, &#34;generic&#34;)
    sine: tuple = (&#34;sine&#34;, &#34;generic&#34;)
    sinedouble: tuple = (&#34;sinedouble&#34;, &#34;generic&#34;)
    sinedoublewithexpdecay: tuple = (&#34;sinedoublewithexpdecay&#34;, &#34;generic&#34;)
    sinedoublewithtwoexpdecay: tuple = (&#34;sinedoublewithtwoexpdecay&#34;, &#34;generic&#34;)
    sinestretchedexponentialdecay: tuple = (&#34;sinestretchedexponentialdecay&#34;, &#34;generic&#34;)
    sinetriple: tuple = (&#34;sinetriple&#34;, &#34;generic&#34;)
    sinetriplewithexpdecay: tuple = (&#34;sinetriplewithexpdecay&#34;, &#34;generic&#34;)
    sinetriplewiththreeexpdecay: tuple = (&#34;sinetriplewiththreeexpdecay&#34;, &#34;generic&#34;)
    twoDgaussian: tuple = (&#34;twoDgaussian&#34;, &#34;generic&#34;)


class AnalysisLogic(FitLogic):
    &#34;&#34;&#34; Class for performing analysis on measurement data &#34;&#34;&#34;
    fit_function = FitMethodsAndEstimators

    def __init__(self):
        super().__init__()
        self.log = logging.getLogger(__name__)

    def _perform_fit(
            self,
            x: np.ndarray,
            y: np.ndarray,
            fit_function: str,
            estimator: str,
            parameters: list[Parameter] = None,
            dims: str = &#34;1d&#34;) -&gt; Tuple[np.ndarray, np.ndarray, ModelResult]:
        fit = {dims: {&#39;default&#39;: {&#39;fit_function&#39;: fit_function, &#39;estimator&#39;: estimator}}}
        user_fit = self.validate_load_fits(fit)

        if parameters:
            user_fit[dims][&#34;default&#34;][&#34;parameters&#34;].add_many(*parameters)

        use_settings = {}
        for key in user_fit[dims][&#34;default&#34;][&#34;parameters&#34;].keys():
            if parameters:
                if key in [p.name for p in parameters]:
                    use_settings[key] = True
                else:
                    use_settings[key] = False
            else:
                use_settings[key] = False
        user_fit[dims][&#34;default&#34;][&#34;use_settings&#34;] = use_settings

        fc = self.make_fit_container(&#34;test&#34;, dims)
        fc.set_fit_functions(user_fit[dims])
        fc.set_current_fit(&#34;default&#34;)
        fit_x, fit_y, result = fc.do_fit(x, y)
        return fit_x, fit_y, result

    def fit(
            self,
            x: str | np.ndarray | pd.Series,
            y: str | np.ndarray | pd.Series,
            fit_function: FitMethodsAndEstimators,
            data: pd.DataFrame = None,
            parameters: list[Parameter] = None
    ) -&gt; Tuple[np.ndarray, np.ndarray, ModelResult]:
        &#34;&#34;&#34;
        Args:
            x: x data, can be string, numpy array or pandas Series
            y: y data, can be string, numpy array or pandas Series
            fit_function: fit function to use
            data: pandas DataFrame containing x and y data, if None x and y must be numpy arrays or pandas Series
            parameters: list of parameters to use in fit (optional)

        Returns:
            Fit x data, fit y data and lmfit ModelResult
        &#34;&#34;&#34;
        if &#34;twoD&#34; in fit_function[0]:
            dims: str = &#34;2d&#34;
        else:
            dims: str = &#34;1d&#34;

        if data is None:
            if isinstance(x, pd.Series) or isinstance(x, pd.Index):
                x: np.ndarray = x.to_numpy()
            if isinstance(y, pd.Series):
                y: np.ndarray = y.to_numpy()
        elif isinstance(data, pd.DataFrame):
            x: np.ndarray = data[x].to_numpy()
            y: np.ndarray = data[y].to_numpy()
        else:
            raise TypeError(&#34;Data must be a pandas DataFrame or None&#34;)

        return self._perform_fit(
            x=x,
            y=y,
            fit_function=fit_function[0],
            estimator=fit_function[1],
            parameters=parameters,
            dims=dims
        )

    def get_all_fits(self) -&gt; Tuple[list, list]:
        &#34;&#34;&#34;Get all available fits

        Returns:
            Tuple with list of 1d and 2d fits
        &#34;&#34;&#34;
        one_d_fits: list = list(self.fit_list[&#39;1d&#39;].keys())
        two_d_fits: list = list(self.fit_list[&#39;2d&#39;].keys())
        self.log.info(f&#34;1d fits: {one_d_fits}\n2d fits: {two_d_fits}&#34;)
        return one_d_fits, two_d_fits

    @staticmethod
    def analyze_mean(
            laser_data: np.ndarray,
            signal_start: float = 100e-9,
            signal_end: float = 300e-9,
            bin_width: float = 1e-9
    ) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Calculate the mean of the signal window.

        Args:
            laser_data: 2D array of laser data
            signal_start: start of the signal window in seconds
            signal_end: end of the signal window in seconds
            bin_width: width of a bin in seconds

        Returns:
            Mean of the signal window and measurement error
        &#34;&#34;&#34;
        # Get number of lasers
        num_of_lasers = laser_data.shape[0]

        if not isinstance(bin_width, float):
            return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

        # Convert the times in seconds to bins (i.e. array indices)
        signal_start_bin = round(signal_start / bin_width)
        signal_end_bin = round(signal_end / bin_width)

        # initialize data arrays for signal and measurement error
        signal_data = np.empty(num_of_lasers, dtype=float)
        error_data = np.empty(num_of_lasers, dtype=float)

        # loop over all laser pulses and analyze them
        for ii, laser_arr in enumerate(laser_data):
            # calculate the mean of the data in the signal window
            signal = laser_arr[signal_start_bin:signal_end_bin].mean()
            signal_sum = laser_arr[signal_start_bin:signal_end_bin].sum()
            signal_error = np.sqrt(signal_sum) / (signal_end_bin - signal_start_bin)

            # Avoid numpy C type variables overflow and NaN values
            if signal &lt; 0 or signal != signal:
                signal_data[ii] = 0.0
                error_data[ii] = 0.0
            else:
                signal_data[ii] = signal
                error_data[ii] = signal_error

        return signal_data, error_data

    @staticmethod
    def analyze_mean_reference(
            laser_data: np.ndarray,
            signal_start: float = 100e-9,
            signal_end: float = 300e-9,
            norm_start: float = 1000e-9,
            norm_end: float = 2000e-9,
            bin_width: float = 1e-9) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Subtracts the mean of the signal window from the mean of the reference window.

        Args:
            laser_data: 2D array of laser data
            signal_start: start of the signal window in seconds
            signal_end: end of the signal window in seconds
            norm_start: start of the reference window in seconds
            norm_end: end of the reference window in seconds
            bin_width: width of a bin in seconds

        Returns:
            Referenced mean of the signal window and measurement error
        &#34;&#34;&#34;
        # Get number of lasers
        num_of_lasers = laser_data.shape[0]

        if not isinstance(bin_width, float):
            return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

        # Convert the times in seconds to bins (i.e. array indices)
        signal_start_bin = round(signal_start / bin_width)
        signal_end_bin = round(signal_end / bin_width)
        norm_start_bin = round(norm_start / bin_width)
        norm_end_bin = round(norm_end / bin_width)

        # initialize data arrays for signal and measurement error
        signal_data = np.empty(num_of_lasers, dtype=float)
        error_data = np.empty(num_of_lasers, dtype=float)

        # loop over all laser pulses and analyze them
        for ii, laser_arr in enumerate(laser_data):
            # calculate the sum and mean of the data in the normalization window
            tmp_data = laser_arr[norm_start_bin:norm_end_bin]
            reference_sum = np.sum(tmp_data)
            reference_mean = (reference_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

            # calculate the sum and mean of the data in the signal window
            tmp_data = laser_arr[signal_start_bin:signal_end_bin]
            signal_sum = np.sum(tmp_data)
            signal_mean = (signal_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

            signal_data[ii] = signal_mean - reference_mean

            # calculate with respect to gaussian error &#39;evolution&#39;
            error_data[ii] = signal_data[ii] * np.sqrt(1 / abs(signal_sum) + 1 / abs(reference_sum))

        return signal_data, error_data

    @staticmethod
    def analyze_mean_norm(
            laser_data: np.ndarray,
            signal_start: float = 100e-9,
            signal_end: float = 300e-9,
            norm_start: float = 1000e-9,
            norm_end=2000e-9,
            bin_width: float = 1e-9
    ) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Divides the mean of the signal window from the mean of the reference window.

        Args:
            laser_data: 2D array of laser data
            signal_start: start of the signal window in seconds
            signal_end: end of the signal window in seconds
            norm_start: start of the reference window in seconds
            norm_end: end of the reference window in seconds
            bin_width: width of a bin in seconds

        Returns:
            Normalized mean of the signal window and measurement error
        &#34;&#34;&#34;
        # Get number of lasers
        num_of_lasers = laser_data.shape[0]

        if not isinstance(bin_width, float):
            return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

        # Convert the times in seconds to bins (i.e. array indices)
        signal_start_bin = round(signal_start / bin_width)
        signal_end_bin = round(signal_end / bin_width)
        norm_start_bin = round(norm_start / bin_width)
        norm_end_bin = round(norm_end / bin_width)

        # initialize data arrays for signal and measurement error
        signal_data = np.empty(num_of_lasers, dtype=float)
        error_data = np.empty(num_of_lasers, dtype=float)

        # loop over all laser pulses and analyze them
        for ii, laser_arr in enumerate(laser_data):
            # calculate the sum and mean of the data in the normalization window
            tmp_data = laser_arr[norm_start_bin:norm_end_bin]
            reference_sum = np.sum(tmp_data)
            reference_mean = (reference_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

            # calculate the sum and mean of the data in the signal window
            tmp_data = laser_arr[signal_start_bin:signal_end_bin]
            signal_sum = np.sum(tmp_data)
            signal_mean = (signal_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

            # Calculate normalized signal while avoiding division by zero
            if reference_mean &gt; 0 and signal_mean &gt;= 0:
                signal_data[ii] = signal_mean / reference_mean
            else:
                signal_data[ii] = 0.0

            # Calculate measurement error while avoiding division by zero
            if reference_sum &gt; 0 and signal_sum &gt; 0:
                # calculate with respect to gaussian error &#39;evolution&#39;
                error_data[ii] = signal_data[ii] * np.sqrt(1 / signal_sum + 1 / reference_sum)
            else:
                error_data[ii] = 0.0

        return signal_data, error_data

    def optimize_raster_odmr_params(
            self,
            measurements: dict[str, MeasurementDataclass],
            num_samples: int = 10,
            num_params: int = 3,
    ) -&gt; Tuple[float, Tuple[float, float, float]]:
        &#34;&#34;&#34;
        This method optimizes the hyperparameters of the ODMR analysis.
        It does so by randomly sampling a subset of the measurements and
        then optimizing the hyperparameters for them.

        Args:
            measurements: A dictionary of measurements to optimize the hyperparameters for.
            num_params: The number of parameters to optimize.
            num_samples: The number of measurements to sample.

        Returns:
            The highest minimum R2 value and the optimized hyperparameters.
        &#34;&#34;&#34;
        r2_threshs: np.ndarray = np.around(np.linspace(start=0.9, stop=0.99, num=num_params), decimals=2)
        thresh_fracs: np.ndarray = np.around(np.linspace(start=0.5, stop=0.9, num=num_params), decimals=1)
        sigma_thresh_fracs: np.ndarray = np.around(np.linspace(start=0.1, stop=0.2, num=num_params), decimals=1)

        odmr_sample: dict = {}
        for k, v in random.sample(sorted(measurements.items()), k=num_samples):
            odmr_sample[k] = v

        highest_min_r2: float = 0
        optimal_params: Tuple[float, float, float] = (0, 0, 0)

        for idx, (r2_thresh, thresh_frac, sigma_thresh_frac) in enumerate(
                product(r2_threshs, thresh_fracs, sigma_thresh_fracs)):
            odmr_sample = self.fit_raster_odmr(
                odmr_sample,
                r2_thresh=r2_thresh,
                thresh_frac=thresh_frac,
                sigma_thresh_frac=sigma_thresh_frac,
                min_thresh=0.01,
                progress_bar=False
            )

            r2s: np.ndarray = np.zeros(len(odmr_sample))
            for _idx, odmr in enumerate(odmr_sample.values()):
                r2s[_idx] = odmr.fit_model.rsquared
            min_r2: float = np.min(r2s)

            if highest_min_r2 &lt; min_r2:
                highest_min_r2 = min_r2
                optimal_params = (r2_thresh, thresh_frac, sigma_thresh_frac)

        return highest_min_r2, optimal_params

    @staticmethod
    def _lorentzian_fitting(
            x: np.ndarray,
            y: np.ndarray,
            model1: Model,
            model2: Model,
            params1: Parameters,
            params2: Parameters,
            r2_thresh: float
    ) -&gt; ModelResult:
        &#34;&#34;&#34; Make Lorentzian fitting for single and double Lorentzian model &#34;&#34;&#34;
        res1 = rof.make_lorentzian_fit(x, y, model1, params1)
        if res1.rsquared &lt; r2_thresh:
            return rof.make_lorentziandouble_fit(x, y, model2, params2)
        return res1

    def fit_raster_odmr(
            self,
            odmr_measurements: dict[str, MeasurementDataclass],
            r2_thresh: float = 0.95,
            thresh_frac: float = 0.5,
            sigma_thresh_frac: float = 0.15,
            min_thresh: float = 0.01,
            extract_pixel_from_filename: bool = True,
            progress_bar: bool = True
    ) -&gt; dict[str, MeasurementDataclass]:
        &#34;&#34;&#34;
        Fit a list of ODMR data to single and double Lorentzian functions

        Args:
            odmr_measurements: Dict of ODMR data in MeasurementDataclasses
            r2_thresh: R^2 Threshold below which a double lorentzian is fitted instead of a single lorentzian
            thresh_frac: Threshold fraction for the peak finding
            min_thresh: Minimum threshold for the peak finding
            sigma_thresh_frac: Change in threshold fraction for the peak finding
            extract_pixel_from_filename: Extract `(row, col)` (in this format) from filename
            progress_bar: Show progress bar

        Returns:
            Dict of ODMR MeasurementDataclass with fit, fit model and pixels attributes set
        &#34;&#34;&#34;

        model1, base_params1 = rof.make_lorentzian_model()
        model2, base_params2 = rof.make_lorentziandouble_model()

        # Generate arguments for the parallel fitting
        args = []
        for odmr in tqdm(odmr_measurements.values(), disable=not progress_bar):
            x = odmr.data[&#34;Freq(MHz)&#34;].to_numpy()
            y = odmr.data[&#34;Counts&#34;].to_numpy()
            _, params1 = rof.estimate_lorentzian_dip(x, y, base_params1)
            _, params2 = rof.estimate_lorentziandouble_dip(x, y, base_params2, thresh_frac, min_thresh,
                                                           sigma_thresh_frac)
            args.append((x, y, model1, model2, params1, params2, r2_thresh))

        # Parallel fitting
        model_results = Parallel(n_jobs=cpu_count())(
            delayed(self._lorentzian_fitting)(
                x, y, model1, model2, params1, params2, r2_thresh) for x, y, model1, model2, params1, params2, r2_thresh
            in
            tqdm(args, disable=not progress_bar)
        )

        x = list(odmr_measurements.values())[0].data[&#34;Freq(MHz)&#34;].to_numpy()
        x_fit = np.linspace(start=x[0], stop=x[-1], num=int(len(x) * 2))

        for odmr, res in zip(odmr_measurements.values(), model_results):

            if len(res.params) == 6:
                # Evaluate a single Lorentzian
                y_fit = model1.eval(x=x_fit, params=res.params)
            else:
                # Evaluate a double Lorentzian
                y_fit = model2.eval(x=x_fit, params=res.params)

            # Plug results into the DataClass
            odmr.fit_model = res
            odmr.fit_data = pd.DataFrame(np.vstack((x_fit, y_fit)).T, columns=[&#34;x_fit&#34;, &#34;y_fit&#34;])

            if extract_pixel_from_filename:
                # Extract the pixel with regex from the filename
                row, col = map(int, re.findall(r&#39;(?&lt;=\().*?(?=\))&#39;, odmr.filename)[0].split(&#34;,&#34;))
                odmr.xy_position = (row, col)

        return odmr_measurements

    @staticmethod
    def average_raster_odmr_pixels(orig_image: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34; Average a NaN pixel to its surrounding pixels.

        Args:
            orig_image: Image with NaN pixels

        Returns:
            Image with NaN pixels replaced by the average of its surrounding pixels
        &#34;&#34;&#34;
        image: np.ndarray = orig_image.copy()
        for row, col in np.argwhere(np.isnan(image)):
            if row == 0:
                pixel_avg = np.nanmean(image[row + 1:row + 2, col - 1:col + 2])
            elif row == image.shape[0] - 1:
                pixel_avg = np.nanmean(image[row - 1:row, col - 1:col + 2])
            elif col == 0:
                pixel_avg = np.nanmean(image[row - 1:row + 2, col + 1:col + 2])
            elif col == image.shape[1] - 1:
                pixel_avg = np.nanmean(image[row - 1:row + 2, col - 1:col])
            else:
                pixel_avg = np.nanmean(image[row - 1:row + 2, col - 1:col + 2])

            image[row, col] = pixel_avg
        return image

    # Aliases for backwards compatibility
    analyse_mean = analyze_mean
    analyse_mean_norm = analyze_mean_norm
    analyse_mean_reference = analyze_mean_reference</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic"><code class="flex name class">
<span>class <span class="ident">AnalysisLogic</span></span>
</code></dt>
<dd>
<div class="desc"><p>Class for performing analysis on measurement data</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AnalysisLogic(FitLogic):
    &#34;&#34;&#34; Class for performing analysis on measurement data &#34;&#34;&#34;
    fit_function = FitMethodsAndEstimators

    def __init__(self):
        super().__init__()
        self.log = logging.getLogger(__name__)

    def _perform_fit(
            self,
            x: np.ndarray,
            y: np.ndarray,
            fit_function: str,
            estimator: str,
            parameters: list[Parameter] = None,
            dims: str = &#34;1d&#34;) -&gt; Tuple[np.ndarray, np.ndarray, ModelResult]:
        fit = {dims: {&#39;default&#39;: {&#39;fit_function&#39;: fit_function, &#39;estimator&#39;: estimator}}}
        user_fit = self.validate_load_fits(fit)

        if parameters:
            user_fit[dims][&#34;default&#34;][&#34;parameters&#34;].add_many(*parameters)

        use_settings = {}
        for key in user_fit[dims][&#34;default&#34;][&#34;parameters&#34;].keys():
            if parameters:
                if key in [p.name for p in parameters]:
                    use_settings[key] = True
                else:
                    use_settings[key] = False
            else:
                use_settings[key] = False
        user_fit[dims][&#34;default&#34;][&#34;use_settings&#34;] = use_settings

        fc = self.make_fit_container(&#34;test&#34;, dims)
        fc.set_fit_functions(user_fit[dims])
        fc.set_current_fit(&#34;default&#34;)
        fit_x, fit_y, result = fc.do_fit(x, y)
        return fit_x, fit_y, result

    def fit(
            self,
            x: str | np.ndarray | pd.Series,
            y: str | np.ndarray | pd.Series,
            fit_function: FitMethodsAndEstimators,
            data: pd.DataFrame = None,
            parameters: list[Parameter] = None
    ) -&gt; Tuple[np.ndarray, np.ndarray, ModelResult]:
        &#34;&#34;&#34;
        Args:
            x: x data, can be string, numpy array or pandas Series
            y: y data, can be string, numpy array or pandas Series
            fit_function: fit function to use
            data: pandas DataFrame containing x and y data, if None x and y must be numpy arrays or pandas Series
            parameters: list of parameters to use in fit (optional)

        Returns:
            Fit x data, fit y data and lmfit ModelResult
        &#34;&#34;&#34;
        if &#34;twoD&#34; in fit_function[0]:
            dims: str = &#34;2d&#34;
        else:
            dims: str = &#34;1d&#34;

        if data is None:
            if isinstance(x, pd.Series) or isinstance(x, pd.Index):
                x: np.ndarray = x.to_numpy()
            if isinstance(y, pd.Series):
                y: np.ndarray = y.to_numpy()
        elif isinstance(data, pd.DataFrame):
            x: np.ndarray = data[x].to_numpy()
            y: np.ndarray = data[y].to_numpy()
        else:
            raise TypeError(&#34;Data must be a pandas DataFrame or None&#34;)

        return self._perform_fit(
            x=x,
            y=y,
            fit_function=fit_function[0],
            estimator=fit_function[1],
            parameters=parameters,
            dims=dims
        )

    def get_all_fits(self) -&gt; Tuple[list, list]:
        &#34;&#34;&#34;Get all available fits

        Returns:
            Tuple with list of 1d and 2d fits
        &#34;&#34;&#34;
        one_d_fits: list = list(self.fit_list[&#39;1d&#39;].keys())
        two_d_fits: list = list(self.fit_list[&#39;2d&#39;].keys())
        self.log.info(f&#34;1d fits: {one_d_fits}\n2d fits: {two_d_fits}&#34;)
        return one_d_fits, two_d_fits

    @staticmethod
    def analyze_mean(
            laser_data: np.ndarray,
            signal_start: float = 100e-9,
            signal_end: float = 300e-9,
            bin_width: float = 1e-9
    ) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Calculate the mean of the signal window.

        Args:
            laser_data: 2D array of laser data
            signal_start: start of the signal window in seconds
            signal_end: end of the signal window in seconds
            bin_width: width of a bin in seconds

        Returns:
            Mean of the signal window and measurement error
        &#34;&#34;&#34;
        # Get number of lasers
        num_of_lasers = laser_data.shape[0]

        if not isinstance(bin_width, float):
            return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

        # Convert the times in seconds to bins (i.e. array indices)
        signal_start_bin = round(signal_start / bin_width)
        signal_end_bin = round(signal_end / bin_width)

        # initialize data arrays for signal and measurement error
        signal_data = np.empty(num_of_lasers, dtype=float)
        error_data = np.empty(num_of_lasers, dtype=float)

        # loop over all laser pulses and analyze them
        for ii, laser_arr in enumerate(laser_data):
            # calculate the mean of the data in the signal window
            signal = laser_arr[signal_start_bin:signal_end_bin].mean()
            signal_sum = laser_arr[signal_start_bin:signal_end_bin].sum()
            signal_error = np.sqrt(signal_sum) / (signal_end_bin - signal_start_bin)

            # Avoid numpy C type variables overflow and NaN values
            if signal &lt; 0 or signal != signal:
                signal_data[ii] = 0.0
                error_data[ii] = 0.0
            else:
                signal_data[ii] = signal
                error_data[ii] = signal_error

        return signal_data, error_data

    @staticmethod
    def analyze_mean_reference(
            laser_data: np.ndarray,
            signal_start: float = 100e-9,
            signal_end: float = 300e-9,
            norm_start: float = 1000e-9,
            norm_end: float = 2000e-9,
            bin_width: float = 1e-9) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Subtracts the mean of the signal window from the mean of the reference window.

        Args:
            laser_data: 2D array of laser data
            signal_start: start of the signal window in seconds
            signal_end: end of the signal window in seconds
            norm_start: start of the reference window in seconds
            norm_end: end of the reference window in seconds
            bin_width: width of a bin in seconds

        Returns:
            Referenced mean of the signal window and measurement error
        &#34;&#34;&#34;
        # Get number of lasers
        num_of_lasers = laser_data.shape[0]

        if not isinstance(bin_width, float):
            return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

        # Convert the times in seconds to bins (i.e. array indices)
        signal_start_bin = round(signal_start / bin_width)
        signal_end_bin = round(signal_end / bin_width)
        norm_start_bin = round(norm_start / bin_width)
        norm_end_bin = round(norm_end / bin_width)

        # initialize data arrays for signal and measurement error
        signal_data = np.empty(num_of_lasers, dtype=float)
        error_data = np.empty(num_of_lasers, dtype=float)

        # loop over all laser pulses and analyze them
        for ii, laser_arr in enumerate(laser_data):
            # calculate the sum and mean of the data in the normalization window
            tmp_data = laser_arr[norm_start_bin:norm_end_bin]
            reference_sum = np.sum(tmp_data)
            reference_mean = (reference_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

            # calculate the sum and mean of the data in the signal window
            tmp_data = laser_arr[signal_start_bin:signal_end_bin]
            signal_sum = np.sum(tmp_data)
            signal_mean = (signal_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

            signal_data[ii] = signal_mean - reference_mean

            # calculate with respect to gaussian error &#39;evolution&#39;
            error_data[ii] = signal_data[ii] * np.sqrt(1 / abs(signal_sum) + 1 / abs(reference_sum))

        return signal_data, error_data

    @staticmethod
    def analyze_mean_norm(
            laser_data: np.ndarray,
            signal_start: float = 100e-9,
            signal_end: float = 300e-9,
            norm_start: float = 1000e-9,
            norm_end=2000e-9,
            bin_width: float = 1e-9
    ) -&gt; Tuple[np.ndarray, np.ndarray]:
        &#34;&#34;&#34;
        Divides the mean of the signal window from the mean of the reference window.

        Args:
            laser_data: 2D array of laser data
            signal_start: start of the signal window in seconds
            signal_end: end of the signal window in seconds
            norm_start: start of the reference window in seconds
            norm_end: end of the reference window in seconds
            bin_width: width of a bin in seconds

        Returns:
            Normalized mean of the signal window and measurement error
        &#34;&#34;&#34;
        # Get number of lasers
        num_of_lasers = laser_data.shape[0]

        if not isinstance(bin_width, float):
            return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

        # Convert the times in seconds to bins (i.e. array indices)
        signal_start_bin = round(signal_start / bin_width)
        signal_end_bin = round(signal_end / bin_width)
        norm_start_bin = round(norm_start / bin_width)
        norm_end_bin = round(norm_end / bin_width)

        # initialize data arrays for signal and measurement error
        signal_data = np.empty(num_of_lasers, dtype=float)
        error_data = np.empty(num_of_lasers, dtype=float)

        # loop over all laser pulses and analyze them
        for ii, laser_arr in enumerate(laser_data):
            # calculate the sum and mean of the data in the normalization window
            tmp_data = laser_arr[norm_start_bin:norm_end_bin]
            reference_sum = np.sum(tmp_data)
            reference_mean = (reference_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

            # calculate the sum and mean of the data in the signal window
            tmp_data = laser_arr[signal_start_bin:signal_end_bin]
            signal_sum = np.sum(tmp_data)
            signal_mean = (signal_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

            # Calculate normalized signal while avoiding division by zero
            if reference_mean &gt; 0 and signal_mean &gt;= 0:
                signal_data[ii] = signal_mean / reference_mean
            else:
                signal_data[ii] = 0.0

            # Calculate measurement error while avoiding division by zero
            if reference_sum &gt; 0 and signal_sum &gt; 0:
                # calculate with respect to gaussian error &#39;evolution&#39;
                error_data[ii] = signal_data[ii] * np.sqrt(1 / signal_sum + 1 / reference_sum)
            else:
                error_data[ii] = 0.0

        return signal_data, error_data

    def optimize_raster_odmr_params(
            self,
            measurements: dict[str, MeasurementDataclass],
            num_samples: int = 10,
            num_params: int = 3,
    ) -&gt; Tuple[float, Tuple[float, float, float]]:
        &#34;&#34;&#34;
        This method optimizes the hyperparameters of the ODMR analysis.
        It does so by randomly sampling a subset of the measurements and
        then optimizing the hyperparameters for them.

        Args:
            measurements: A dictionary of measurements to optimize the hyperparameters for.
            num_params: The number of parameters to optimize.
            num_samples: The number of measurements to sample.

        Returns:
            The highest minimum R2 value and the optimized hyperparameters.
        &#34;&#34;&#34;
        r2_threshs: np.ndarray = np.around(np.linspace(start=0.9, stop=0.99, num=num_params), decimals=2)
        thresh_fracs: np.ndarray = np.around(np.linspace(start=0.5, stop=0.9, num=num_params), decimals=1)
        sigma_thresh_fracs: np.ndarray = np.around(np.linspace(start=0.1, stop=0.2, num=num_params), decimals=1)

        odmr_sample: dict = {}
        for k, v in random.sample(sorted(measurements.items()), k=num_samples):
            odmr_sample[k] = v

        highest_min_r2: float = 0
        optimal_params: Tuple[float, float, float] = (0, 0, 0)

        for idx, (r2_thresh, thresh_frac, sigma_thresh_frac) in enumerate(
                product(r2_threshs, thresh_fracs, sigma_thresh_fracs)):
            odmr_sample = self.fit_raster_odmr(
                odmr_sample,
                r2_thresh=r2_thresh,
                thresh_frac=thresh_frac,
                sigma_thresh_frac=sigma_thresh_frac,
                min_thresh=0.01,
                progress_bar=False
            )

            r2s: np.ndarray = np.zeros(len(odmr_sample))
            for _idx, odmr in enumerate(odmr_sample.values()):
                r2s[_idx] = odmr.fit_model.rsquared
            min_r2: float = np.min(r2s)

            if highest_min_r2 &lt; min_r2:
                highest_min_r2 = min_r2
                optimal_params = (r2_thresh, thresh_frac, sigma_thresh_frac)

        return highest_min_r2, optimal_params

    @staticmethod
    def _lorentzian_fitting(
            x: np.ndarray,
            y: np.ndarray,
            model1: Model,
            model2: Model,
            params1: Parameters,
            params2: Parameters,
            r2_thresh: float
    ) -&gt; ModelResult:
        &#34;&#34;&#34; Make Lorentzian fitting for single and double Lorentzian model &#34;&#34;&#34;
        res1 = rof.make_lorentzian_fit(x, y, model1, params1)
        if res1.rsquared &lt; r2_thresh:
            return rof.make_lorentziandouble_fit(x, y, model2, params2)
        return res1

    def fit_raster_odmr(
            self,
            odmr_measurements: dict[str, MeasurementDataclass],
            r2_thresh: float = 0.95,
            thresh_frac: float = 0.5,
            sigma_thresh_frac: float = 0.15,
            min_thresh: float = 0.01,
            extract_pixel_from_filename: bool = True,
            progress_bar: bool = True
    ) -&gt; dict[str, MeasurementDataclass]:
        &#34;&#34;&#34;
        Fit a list of ODMR data to single and double Lorentzian functions

        Args:
            odmr_measurements: Dict of ODMR data in MeasurementDataclasses
            r2_thresh: R^2 Threshold below which a double lorentzian is fitted instead of a single lorentzian
            thresh_frac: Threshold fraction for the peak finding
            min_thresh: Minimum threshold for the peak finding
            sigma_thresh_frac: Change in threshold fraction for the peak finding
            extract_pixel_from_filename: Extract `(row, col)` (in this format) from filename
            progress_bar: Show progress bar

        Returns:
            Dict of ODMR MeasurementDataclass with fit, fit model and pixels attributes set
        &#34;&#34;&#34;

        model1, base_params1 = rof.make_lorentzian_model()
        model2, base_params2 = rof.make_lorentziandouble_model()

        # Generate arguments for the parallel fitting
        args = []
        for odmr in tqdm(odmr_measurements.values(), disable=not progress_bar):
            x = odmr.data[&#34;Freq(MHz)&#34;].to_numpy()
            y = odmr.data[&#34;Counts&#34;].to_numpy()
            _, params1 = rof.estimate_lorentzian_dip(x, y, base_params1)
            _, params2 = rof.estimate_lorentziandouble_dip(x, y, base_params2, thresh_frac, min_thresh,
                                                           sigma_thresh_frac)
            args.append((x, y, model1, model2, params1, params2, r2_thresh))

        # Parallel fitting
        model_results = Parallel(n_jobs=cpu_count())(
            delayed(self._lorentzian_fitting)(
                x, y, model1, model2, params1, params2, r2_thresh) for x, y, model1, model2, params1, params2, r2_thresh
            in
            tqdm(args, disable=not progress_bar)
        )

        x = list(odmr_measurements.values())[0].data[&#34;Freq(MHz)&#34;].to_numpy()
        x_fit = np.linspace(start=x[0], stop=x[-1], num=int(len(x) * 2))

        for odmr, res in zip(odmr_measurements.values(), model_results):

            if len(res.params) == 6:
                # Evaluate a single Lorentzian
                y_fit = model1.eval(x=x_fit, params=res.params)
            else:
                # Evaluate a double Lorentzian
                y_fit = model2.eval(x=x_fit, params=res.params)

            # Plug results into the DataClass
            odmr.fit_model = res
            odmr.fit_data = pd.DataFrame(np.vstack((x_fit, y_fit)).T, columns=[&#34;x_fit&#34;, &#34;y_fit&#34;])

            if extract_pixel_from_filename:
                # Extract the pixel with regex from the filename
                row, col = map(int, re.findall(r&#39;(?&lt;=\().*?(?=\))&#39;, odmr.filename)[0].split(&#34;,&#34;))
                odmr.xy_position = (row, col)

        return odmr_measurements

    @staticmethod
    def average_raster_odmr_pixels(orig_image: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34; Average a NaN pixel to its surrounding pixels.

        Args:
            orig_image: Image with NaN pixels

        Returns:
            Image with NaN pixels replaced by the average of its surrounding pixels
        &#34;&#34;&#34;
        image: np.ndarray = orig_image.copy()
        for row, col in np.argwhere(np.isnan(image)):
            if row == 0:
                pixel_avg = np.nanmean(image[row + 1:row + 2, col - 1:col + 2])
            elif row == image.shape[0] - 1:
                pixel_avg = np.nanmean(image[row - 1:row, col - 1:col + 2])
            elif col == 0:
                pixel_avg = np.nanmean(image[row - 1:row + 2, col + 1:col + 2])
            elif col == image.shape[1] - 1:
                pixel_avg = np.nanmean(image[row - 1:row + 2, col - 1:col])
            else:
                pixel_avg = np.nanmean(image[row - 1:row + 2, col - 1:col + 2])

            image[row, col] = pixel_avg
        return image

    # Aliases for backwards compatibility
    analyse_mean = analyze_mean
    analyse_mean_norm = analyze_mean_norm
    analyse_mean_reference = analyze_mean_reference</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>qudi_hira_analysis._qudi_fit_logic.FitLogic</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="qudi_hira_analysis.data_handler.DataHandler" href="data_handler.html#qudi_hira_analysis.data_handler.DataHandler">DataHandler</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.fit_function"><code class="name">var <span class="ident">fit_function</span></code></dt>
<dd>
<div class="desc"><p>Class for storing fit methods and estimators.
Fit methods are stored as tuples of (method, estimator)
where method is the name of the fit method and estimator is the name of the estimator.</p></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyse_mean"><code class="name flex">
<span>def <span class="ident">analyse_mean</span></span>(<span>laser_data: np.ndarray, signal_start: float = 1e-07, signal_end: float = 3e-07, bin_width: float = 1e-09) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the mean of the signal window.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>laser_data</code></strong></dt>
<dd>2D array of laser data</dd>
<dt><strong><code>signal_start</code></strong></dt>
<dd>start of the signal window in seconds</dd>
<dt><strong><code>signal_end</code></strong></dt>
<dd>end of the signal window in seconds</dd>
<dt><strong><code>bin_width</code></strong></dt>
<dd>width of a bin in seconds</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Mean of the signal window and measurement error</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def analyze_mean(
        laser_data: np.ndarray,
        signal_start: float = 100e-9,
        signal_end: float = 300e-9,
        bin_width: float = 1e-9
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;
    Calculate the mean of the signal window.

    Args:
        laser_data: 2D array of laser data
        signal_start: start of the signal window in seconds
        signal_end: end of the signal window in seconds
        bin_width: width of a bin in seconds

    Returns:
        Mean of the signal window and measurement error
    &#34;&#34;&#34;
    # Get number of lasers
    num_of_lasers = laser_data.shape[0]

    if not isinstance(bin_width, float):
        return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

    # Convert the times in seconds to bins (i.e. array indices)
    signal_start_bin = round(signal_start / bin_width)
    signal_end_bin = round(signal_end / bin_width)

    # initialize data arrays for signal and measurement error
    signal_data = np.empty(num_of_lasers, dtype=float)
    error_data = np.empty(num_of_lasers, dtype=float)

    # loop over all laser pulses and analyze them
    for ii, laser_arr in enumerate(laser_data):
        # calculate the mean of the data in the signal window
        signal = laser_arr[signal_start_bin:signal_end_bin].mean()
        signal_sum = laser_arr[signal_start_bin:signal_end_bin].sum()
        signal_error = np.sqrt(signal_sum) / (signal_end_bin - signal_start_bin)

        # Avoid numpy C type variables overflow and NaN values
        if signal &lt; 0 or signal != signal:
            signal_data[ii] = 0.0
            error_data[ii] = 0.0
        else:
            signal_data[ii] = signal
            error_data[ii] = signal_error

    return signal_data, error_data</code></pre>
</details>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyse_mean_norm"><code class="name flex">
<span>def <span class="ident">analyse_mean_norm</span></span>(<span>laser_data: np.ndarray, signal_start: float = 1e-07, signal_end: float = 3e-07, norm_start: float = 1e-06, norm_end=2e-06, bin_width: float = 1e-09) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Divides the mean of the signal window from the mean of the reference window.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>laser_data</code></strong></dt>
<dd>2D array of laser data</dd>
<dt><strong><code>signal_start</code></strong></dt>
<dd>start of the signal window in seconds</dd>
<dt><strong><code>signal_end</code></strong></dt>
<dd>end of the signal window in seconds</dd>
<dt><strong><code>norm_start</code></strong></dt>
<dd>start of the reference window in seconds</dd>
<dt><strong><code>norm_end</code></strong></dt>
<dd>end of the reference window in seconds</dd>
<dt><strong><code>bin_width</code></strong></dt>
<dd>width of a bin in seconds</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Normalized mean of the signal window and measurement error</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def analyze_mean_norm(
        laser_data: np.ndarray,
        signal_start: float = 100e-9,
        signal_end: float = 300e-9,
        norm_start: float = 1000e-9,
        norm_end=2000e-9,
        bin_width: float = 1e-9
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;
    Divides the mean of the signal window from the mean of the reference window.

    Args:
        laser_data: 2D array of laser data
        signal_start: start of the signal window in seconds
        signal_end: end of the signal window in seconds
        norm_start: start of the reference window in seconds
        norm_end: end of the reference window in seconds
        bin_width: width of a bin in seconds

    Returns:
        Normalized mean of the signal window and measurement error
    &#34;&#34;&#34;
    # Get number of lasers
    num_of_lasers = laser_data.shape[0]

    if not isinstance(bin_width, float):
        return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

    # Convert the times in seconds to bins (i.e. array indices)
    signal_start_bin = round(signal_start / bin_width)
    signal_end_bin = round(signal_end / bin_width)
    norm_start_bin = round(norm_start / bin_width)
    norm_end_bin = round(norm_end / bin_width)

    # initialize data arrays for signal and measurement error
    signal_data = np.empty(num_of_lasers, dtype=float)
    error_data = np.empty(num_of_lasers, dtype=float)

    # loop over all laser pulses and analyze them
    for ii, laser_arr in enumerate(laser_data):
        # calculate the sum and mean of the data in the normalization window
        tmp_data = laser_arr[norm_start_bin:norm_end_bin]
        reference_sum = np.sum(tmp_data)
        reference_mean = (reference_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

        # calculate the sum and mean of the data in the signal window
        tmp_data = laser_arr[signal_start_bin:signal_end_bin]
        signal_sum = np.sum(tmp_data)
        signal_mean = (signal_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

        # Calculate normalized signal while avoiding division by zero
        if reference_mean &gt; 0 and signal_mean &gt;= 0:
            signal_data[ii] = signal_mean / reference_mean
        else:
            signal_data[ii] = 0.0

        # Calculate measurement error while avoiding division by zero
        if reference_sum &gt; 0 and signal_sum &gt; 0:
            # calculate with respect to gaussian error &#39;evolution&#39;
            error_data[ii] = signal_data[ii] * np.sqrt(1 / signal_sum + 1 / reference_sum)
        else:
            error_data[ii] = 0.0

    return signal_data, error_data</code></pre>
</details>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyse_mean_reference"><code class="name flex">
<span>def <span class="ident">analyse_mean_reference</span></span>(<span>laser_data: np.ndarray, signal_start: float = 1e-07, signal_end: float = 3e-07, norm_start: float = 1e-06, norm_end: float = 2e-06, bin_width: float = 1e-09) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Subtracts the mean of the signal window from the mean of the reference window.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>laser_data</code></strong></dt>
<dd>2D array of laser data</dd>
<dt><strong><code>signal_start</code></strong></dt>
<dd>start of the signal window in seconds</dd>
<dt><strong><code>signal_end</code></strong></dt>
<dd>end of the signal window in seconds</dd>
<dt><strong><code>norm_start</code></strong></dt>
<dd>start of the reference window in seconds</dd>
<dt><strong><code>norm_end</code></strong></dt>
<dd>end of the reference window in seconds</dd>
<dt><strong><code>bin_width</code></strong></dt>
<dd>width of a bin in seconds</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Referenced mean of the signal window and measurement error</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def analyze_mean_reference(
        laser_data: np.ndarray,
        signal_start: float = 100e-9,
        signal_end: float = 300e-9,
        norm_start: float = 1000e-9,
        norm_end: float = 2000e-9,
        bin_width: float = 1e-9) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;
    Subtracts the mean of the signal window from the mean of the reference window.

    Args:
        laser_data: 2D array of laser data
        signal_start: start of the signal window in seconds
        signal_end: end of the signal window in seconds
        norm_start: start of the reference window in seconds
        norm_end: end of the reference window in seconds
        bin_width: width of a bin in seconds

    Returns:
        Referenced mean of the signal window and measurement error
    &#34;&#34;&#34;
    # Get number of lasers
    num_of_lasers = laser_data.shape[0]

    if not isinstance(bin_width, float):
        return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

    # Convert the times in seconds to bins (i.e. array indices)
    signal_start_bin = round(signal_start / bin_width)
    signal_end_bin = round(signal_end / bin_width)
    norm_start_bin = round(norm_start / bin_width)
    norm_end_bin = round(norm_end / bin_width)

    # initialize data arrays for signal and measurement error
    signal_data = np.empty(num_of_lasers, dtype=float)
    error_data = np.empty(num_of_lasers, dtype=float)

    # loop over all laser pulses and analyze them
    for ii, laser_arr in enumerate(laser_data):
        # calculate the sum and mean of the data in the normalization window
        tmp_data = laser_arr[norm_start_bin:norm_end_bin]
        reference_sum = np.sum(tmp_data)
        reference_mean = (reference_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

        # calculate the sum and mean of the data in the signal window
        tmp_data = laser_arr[signal_start_bin:signal_end_bin]
        signal_sum = np.sum(tmp_data)
        signal_mean = (signal_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

        signal_data[ii] = signal_mean - reference_mean

        # calculate with respect to gaussian error &#39;evolution&#39;
        error_data[ii] = signal_data[ii] * np.sqrt(1 / abs(signal_sum) + 1 / abs(reference_sum))

    return signal_data, error_data</code></pre>
</details>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyze_mean"><code class="name flex">
<span>def <span class="ident">analyze_mean</span></span>(<span>laser_data: np.ndarray, signal_start: float = 1e-07, signal_end: float = 3e-07, bin_width: float = 1e-09) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the mean of the signal window.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>laser_data</code></strong></dt>
<dd>2D array of laser data</dd>
<dt><strong><code>signal_start</code></strong></dt>
<dd>start of the signal window in seconds</dd>
<dt><strong><code>signal_end</code></strong></dt>
<dd>end of the signal window in seconds</dd>
<dt><strong><code>bin_width</code></strong></dt>
<dd>width of a bin in seconds</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Mean of the signal window and measurement error</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def analyze_mean(
        laser_data: np.ndarray,
        signal_start: float = 100e-9,
        signal_end: float = 300e-9,
        bin_width: float = 1e-9
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;
    Calculate the mean of the signal window.

    Args:
        laser_data: 2D array of laser data
        signal_start: start of the signal window in seconds
        signal_end: end of the signal window in seconds
        bin_width: width of a bin in seconds

    Returns:
        Mean of the signal window and measurement error
    &#34;&#34;&#34;
    # Get number of lasers
    num_of_lasers = laser_data.shape[0]

    if not isinstance(bin_width, float):
        return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

    # Convert the times in seconds to bins (i.e. array indices)
    signal_start_bin = round(signal_start / bin_width)
    signal_end_bin = round(signal_end / bin_width)

    # initialize data arrays for signal and measurement error
    signal_data = np.empty(num_of_lasers, dtype=float)
    error_data = np.empty(num_of_lasers, dtype=float)

    # loop over all laser pulses and analyze them
    for ii, laser_arr in enumerate(laser_data):
        # calculate the mean of the data in the signal window
        signal = laser_arr[signal_start_bin:signal_end_bin].mean()
        signal_sum = laser_arr[signal_start_bin:signal_end_bin].sum()
        signal_error = np.sqrt(signal_sum) / (signal_end_bin - signal_start_bin)

        # Avoid numpy C type variables overflow and NaN values
        if signal &lt; 0 or signal != signal:
            signal_data[ii] = 0.0
            error_data[ii] = 0.0
        else:
            signal_data[ii] = signal
            error_data[ii] = signal_error

    return signal_data, error_data</code></pre>
</details>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyze_mean_norm"><code class="name flex">
<span>def <span class="ident">analyze_mean_norm</span></span>(<span>laser_data: np.ndarray, signal_start: float = 1e-07, signal_end: float = 3e-07, norm_start: float = 1e-06, norm_end=2e-06, bin_width: float = 1e-09) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Divides the mean of the signal window from the mean of the reference window.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>laser_data</code></strong></dt>
<dd>2D array of laser data</dd>
<dt><strong><code>signal_start</code></strong></dt>
<dd>start of the signal window in seconds</dd>
<dt><strong><code>signal_end</code></strong></dt>
<dd>end of the signal window in seconds</dd>
<dt><strong><code>norm_start</code></strong></dt>
<dd>start of the reference window in seconds</dd>
<dt><strong><code>norm_end</code></strong></dt>
<dd>end of the reference window in seconds</dd>
<dt><strong><code>bin_width</code></strong></dt>
<dd>width of a bin in seconds</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Normalized mean of the signal window and measurement error</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def analyze_mean_norm(
        laser_data: np.ndarray,
        signal_start: float = 100e-9,
        signal_end: float = 300e-9,
        norm_start: float = 1000e-9,
        norm_end=2000e-9,
        bin_width: float = 1e-9
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;
    Divides the mean of the signal window from the mean of the reference window.

    Args:
        laser_data: 2D array of laser data
        signal_start: start of the signal window in seconds
        signal_end: end of the signal window in seconds
        norm_start: start of the reference window in seconds
        norm_end: end of the reference window in seconds
        bin_width: width of a bin in seconds

    Returns:
        Normalized mean of the signal window and measurement error
    &#34;&#34;&#34;
    # Get number of lasers
    num_of_lasers = laser_data.shape[0]

    if not isinstance(bin_width, float):
        return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

    # Convert the times in seconds to bins (i.e. array indices)
    signal_start_bin = round(signal_start / bin_width)
    signal_end_bin = round(signal_end / bin_width)
    norm_start_bin = round(norm_start / bin_width)
    norm_end_bin = round(norm_end / bin_width)

    # initialize data arrays for signal and measurement error
    signal_data = np.empty(num_of_lasers, dtype=float)
    error_data = np.empty(num_of_lasers, dtype=float)

    # loop over all laser pulses and analyze them
    for ii, laser_arr in enumerate(laser_data):
        # calculate the sum and mean of the data in the normalization window
        tmp_data = laser_arr[norm_start_bin:norm_end_bin]
        reference_sum = np.sum(tmp_data)
        reference_mean = (reference_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

        # calculate the sum and mean of the data in the signal window
        tmp_data = laser_arr[signal_start_bin:signal_end_bin]
        signal_sum = np.sum(tmp_data)
        signal_mean = (signal_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

        # Calculate normalized signal while avoiding division by zero
        if reference_mean &gt; 0 and signal_mean &gt;= 0:
            signal_data[ii] = signal_mean / reference_mean
        else:
            signal_data[ii] = 0.0

        # Calculate measurement error while avoiding division by zero
        if reference_sum &gt; 0 and signal_sum &gt; 0:
            # calculate with respect to gaussian error &#39;evolution&#39;
            error_data[ii] = signal_data[ii] * np.sqrt(1 / signal_sum + 1 / reference_sum)
        else:
            error_data[ii] = 0.0

    return signal_data, error_data</code></pre>
</details>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyze_mean_reference"><code class="name flex">
<span>def <span class="ident">analyze_mean_reference</span></span>(<span>laser_data: np.ndarray, signal_start: float = 1e-07, signal_end: float = 3e-07, norm_start: float = 1e-06, norm_end: float = 2e-06, bin_width: float = 1e-09) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Subtracts the mean of the signal window from the mean of the reference window.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>laser_data</code></strong></dt>
<dd>2D array of laser data</dd>
<dt><strong><code>signal_start</code></strong></dt>
<dd>start of the signal window in seconds</dd>
<dt><strong><code>signal_end</code></strong></dt>
<dd>end of the signal window in seconds</dd>
<dt><strong><code>norm_start</code></strong></dt>
<dd>start of the reference window in seconds</dd>
<dt><strong><code>norm_end</code></strong></dt>
<dd>end of the reference window in seconds</dd>
<dt><strong><code>bin_width</code></strong></dt>
<dd>width of a bin in seconds</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Referenced mean of the signal window and measurement error</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def analyze_mean_reference(
        laser_data: np.ndarray,
        signal_start: float = 100e-9,
        signal_end: float = 300e-9,
        norm_start: float = 1000e-9,
        norm_end: float = 2000e-9,
        bin_width: float = 1e-9) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;
    Subtracts the mean of the signal window from the mean of the reference window.

    Args:
        laser_data: 2D array of laser data
        signal_start: start of the signal window in seconds
        signal_end: end of the signal window in seconds
        norm_start: start of the reference window in seconds
        norm_end: end of the reference window in seconds
        bin_width: width of a bin in seconds

    Returns:
        Referenced mean of the signal window and measurement error
    &#34;&#34;&#34;
    # Get number of lasers
    num_of_lasers = laser_data.shape[0]

    if not isinstance(bin_width, float):
        return np.zeros(num_of_lasers), np.zeros(num_of_lasers)

    # Convert the times in seconds to bins (i.e. array indices)
    signal_start_bin = round(signal_start / bin_width)
    signal_end_bin = round(signal_end / bin_width)
    norm_start_bin = round(norm_start / bin_width)
    norm_end_bin = round(norm_end / bin_width)

    # initialize data arrays for signal and measurement error
    signal_data = np.empty(num_of_lasers, dtype=float)
    error_data = np.empty(num_of_lasers, dtype=float)

    # loop over all laser pulses and analyze them
    for ii, laser_arr in enumerate(laser_data):
        # calculate the sum and mean of the data in the normalization window
        tmp_data = laser_arr[norm_start_bin:norm_end_bin]
        reference_sum = np.sum(tmp_data)
        reference_mean = (reference_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

        # calculate the sum and mean of the data in the signal window
        tmp_data = laser_arr[signal_start_bin:signal_end_bin]
        signal_sum = np.sum(tmp_data)
        signal_mean = (signal_sum / len(tmp_data)) if len(tmp_data) != 0 else 0.0

        signal_data[ii] = signal_mean - reference_mean

        # calculate with respect to gaussian error &#39;evolution&#39;
        error_data[ii] = signal_data[ii] * np.sqrt(1 / abs(signal_sum) + 1 / abs(reference_sum))

    return signal_data, error_data</code></pre>
</details>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.average_raster_odmr_pixels"><code class="name flex">
<span>def <span class="ident">average_raster_odmr_pixels</span></span>(<span>orig_image: np.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Average a NaN pixel to its surrounding pixels.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>orig_image</code></strong></dt>
<dd>Image with NaN pixels</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Image with NaN pixels replaced by the average of its surrounding pixels</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def average_raster_odmr_pixels(orig_image: np.ndarray) -&gt; np.ndarray:
    &#34;&#34;&#34; Average a NaN pixel to its surrounding pixels.

    Args:
        orig_image: Image with NaN pixels

    Returns:
        Image with NaN pixels replaced by the average of its surrounding pixels
    &#34;&#34;&#34;
    image: np.ndarray = orig_image.copy()
    for row, col in np.argwhere(np.isnan(image)):
        if row == 0:
            pixel_avg = np.nanmean(image[row + 1:row + 2, col - 1:col + 2])
        elif row == image.shape[0] - 1:
            pixel_avg = np.nanmean(image[row - 1:row, col - 1:col + 2])
        elif col == 0:
            pixel_avg = np.nanmean(image[row - 1:row + 2, col + 1:col + 2])
        elif col == image.shape[1] - 1:
            pixel_avg = np.nanmean(image[row - 1:row + 2, col - 1:col])
        else:
            pixel_avg = np.nanmean(image[row - 1:row + 2, col - 1:col + 2])

        image[row, col] = pixel_avg
    return image</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, x: str | np.ndarray | pd.Series, y: str | np.ndarray | pd.Series, fit_function: <a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators">FitMethodsAndEstimators</a>, data: pd.DataFrame = None, parameters: list[Parameter] = None) ‑> Tuple[np.ndarray, np.ndarray, ModelResult]</span>
</code></dt>
<dd>
<div class="desc"><h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong></dt>
<dd>x data, can be string, numpy array or pandas Series</dd>
<dt><strong><code>y</code></strong></dt>
<dd>y data, can be string, numpy array or pandas Series</dd>
<dt><strong><code>fit_function</code></strong></dt>
<dd>fit function to use</dd>
<dt><strong><code>data</code></strong></dt>
<dd>pandas DataFrame containing x and y data, if None x and y must be numpy arrays or pandas Series</dd>
<dt><strong><code>parameters</code></strong></dt>
<dd>list of parameters to use in fit (optional)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Fit x data, fit y data and lmfit ModelResult</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(
        self,
        x: str | np.ndarray | pd.Series,
        y: str | np.ndarray | pd.Series,
        fit_function: FitMethodsAndEstimators,
        data: pd.DataFrame = None,
        parameters: list[Parameter] = None
) -&gt; Tuple[np.ndarray, np.ndarray, ModelResult]:
    &#34;&#34;&#34;
    Args:
        x: x data, can be string, numpy array or pandas Series
        y: y data, can be string, numpy array or pandas Series
        fit_function: fit function to use
        data: pandas DataFrame containing x and y data, if None x and y must be numpy arrays or pandas Series
        parameters: list of parameters to use in fit (optional)

    Returns:
        Fit x data, fit y data and lmfit ModelResult
    &#34;&#34;&#34;
    if &#34;twoD&#34; in fit_function[0]:
        dims: str = &#34;2d&#34;
    else:
        dims: str = &#34;1d&#34;

    if data is None:
        if isinstance(x, pd.Series) or isinstance(x, pd.Index):
            x: np.ndarray = x.to_numpy()
        if isinstance(y, pd.Series):
            y: np.ndarray = y.to_numpy()
    elif isinstance(data, pd.DataFrame):
        x: np.ndarray = data[x].to_numpy()
        y: np.ndarray = data[y].to_numpy()
    else:
        raise TypeError(&#34;Data must be a pandas DataFrame or None&#34;)

    return self._perform_fit(
        x=x,
        y=y,
        fit_function=fit_function[0],
        estimator=fit_function[1],
        parameters=parameters,
        dims=dims
    )</code></pre>
</details>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.fit_raster_odmr"><code class="name flex">
<span>def <span class="ident">fit_raster_odmr</span></span>(<span>self, odmr_measurements: dict[str, MeasurementDataclass], r2_thresh: float = 0.95, thresh_frac: float = 0.5, sigma_thresh_frac: float = 0.15, min_thresh: float = 0.01, extract_pixel_from_filename: bool = True, progress_bar: bool = True) ‑> dict[str, MeasurementDataclass]</span>
</code></dt>
<dd>
<div class="desc"><p>Fit a list of ODMR data to single and double Lorentzian functions</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>odmr_measurements</code></strong></dt>
<dd>Dict of ODMR data in MeasurementDataclasses</dd>
<dt><strong><code>r2_thresh</code></strong></dt>
<dd>R^2 Threshold below which a double lorentzian is fitted instead of a single lorentzian</dd>
<dt><strong><code>thresh_frac</code></strong></dt>
<dd>Threshold fraction for the peak finding</dd>
<dt><strong><code>min_thresh</code></strong></dt>
<dd>Minimum threshold for the peak finding</dd>
<dt><strong><code>sigma_thresh_frac</code></strong></dt>
<dd>Change in threshold fraction for the peak finding</dd>
<dt><strong><code>extract_pixel_from_filename</code></strong></dt>
<dd>Extract <code>(row, col)</code> (in this format) from filename</dd>
<dt><strong><code>progress_bar</code></strong></dt>
<dd>Show progress bar</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Dict of ODMR MeasurementDataclass with fit, fit model and pixels attributes set</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit_raster_odmr(
        self,
        odmr_measurements: dict[str, MeasurementDataclass],
        r2_thresh: float = 0.95,
        thresh_frac: float = 0.5,
        sigma_thresh_frac: float = 0.15,
        min_thresh: float = 0.01,
        extract_pixel_from_filename: bool = True,
        progress_bar: bool = True
) -&gt; dict[str, MeasurementDataclass]:
    &#34;&#34;&#34;
    Fit a list of ODMR data to single and double Lorentzian functions

    Args:
        odmr_measurements: Dict of ODMR data in MeasurementDataclasses
        r2_thresh: R^2 Threshold below which a double lorentzian is fitted instead of a single lorentzian
        thresh_frac: Threshold fraction for the peak finding
        min_thresh: Minimum threshold for the peak finding
        sigma_thresh_frac: Change in threshold fraction for the peak finding
        extract_pixel_from_filename: Extract `(row, col)` (in this format) from filename
        progress_bar: Show progress bar

    Returns:
        Dict of ODMR MeasurementDataclass with fit, fit model and pixels attributes set
    &#34;&#34;&#34;

    model1, base_params1 = rof.make_lorentzian_model()
    model2, base_params2 = rof.make_lorentziandouble_model()

    # Generate arguments for the parallel fitting
    args = []
    for odmr in tqdm(odmr_measurements.values(), disable=not progress_bar):
        x = odmr.data[&#34;Freq(MHz)&#34;].to_numpy()
        y = odmr.data[&#34;Counts&#34;].to_numpy()
        _, params1 = rof.estimate_lorentzian_dip(x, y, base_params1)
        _, params2 = rof.estimate_lorentziandouble_dip(x, y, base_params2, thresh_frac, min_thresh,
                                                       sigma_thresh_frac)
        args.append((x, y, model1, model2, params1, params2, r2_thresh))

    # Parallel fitting
    model_results = Parallel(n_jobs=cpu_count())(
        delayed(self._lorentzian_fitting)(
            x, y, model1, model2, params1, params2, r2_thresh) for x, y, model1, model2, params1, params2, r2_thresh
        in
        tqdm(args, disable=not progress_bar)
    )

    x = list(odmr_measurements.values())[0].data[&#34;Freq(MHz)&#34;].to_numpy()
    x_fit = np.linspace(start=x[0], stop=x[-1], num=int(len(x) * 2))

    for odmr, res in zip(odmr_measurements.values(), model_results):

        if len(res.params) == 6:
            # Evaluate a single Lorentzian
            y_fit = model1.eval(x=x_fit, params=res.params)
        else:
            # Evaluate a double Lorentzian
            y_fit = model2.eval(x=x_fit, params=res.params)

        # Plug results into the DataClass
        odmr.fit_model = res
        odmr.fit_data = pd.DataFrame(np.vstack((x_fit, y_fit)).T, columns=[&#34;x_fit&#34;, &#34;y_fit&#34;])

        if extract_pixel_from_filename:
            # Extract the pixel with regex from the filename
            row, col = map(int, re.findall(r&#39;(?&lt;=\().*?(?=\))&#39;, odmr.filename)[0].split(&#34;,&#34;))
            odmr.xy_position = (row, col)

    return odmr_measurements</code></pre>
</details>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.get_all_fits"><code class="name flex">
<span>def <span class="ident">get_all_fits</span></span>(<span>self) ‑> Tuple[list, list]</span>
</code></dt>
<dd>
<div class="desc"><p>Get all available fits</p>
<h2 id="returns">Returns</h2>
<p>Tuple with list of 1d and 2d fits</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_all_fits(self) -&gt; Tuple[list, list]:
    &#34;&#34;&#34;Get all available fits

    Returns:
        Tuple with list of 1d and 2d fits
    &#34;&#34;&#34;
    one_d_fits: list = list(self.fit_list[&#39;1d&#39;].keys())
    two_d_fits: list = list(self.fit_list[&#39;2d&#39;].keys())
    self.log.info(f&#34;1d fits: {one_d_fits}\n2d fits: {two_d_fits}&#34;)
    return one_d_fits, two_d_fits</code></pre>
</details>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.AnalysisLogic.optimize_raster_odmr_params"><code class="name flex">
<span>def <span class="ident">optimize_raster_odmr_params</span></span>(<span>self, measurements: dict[str, MeasurementDataclass], num_samples: int = 10, num_params: int = 3) ‑> Tuple[float, Tuple[float, float, float]]</span>
</code></dt>
<dd>
<div class="desc"><p>This method optimizes the hyperparameters of the ODMR analysis.
It does so by randomly sampling a subset of the measurements and
then optimizing the hyperparameters for them.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>measurements</code></strong></dt>
<dd>A dictionary of measurements to optimize the hyperparameters for.</dd>
<dt><strong><code>num_params</code></strong></dt>
<dd>The number of parameters to optimize.</dd>
<dt><strong><code>num_samples</code></strong></dt>
<dd>The number of measurements to sample.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The highest minimum R2 value and the optimized hyperparameters.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def optimize_raster_odmr_params(
        self,
        measurements: dict[str, MeasurementDataclass],
        num_samples: int = 10,
        num_params: int = 3,
) -&gt; Tuple[float, Tuple[float, float, float]]:
    &#34;&#34;&#34;
    This method optimizes the hyperparameters of the ODMR analysis.
    It does so by randomly sampling a subset of the measurements and
    then optimizing the hyperparameters for them.

    Args:
        measurements: A dictionary of measurements to optimize the hyperparameters for.
        num_params: The number of parameters to optimize.
        num_samples: The number of measurements to sample.

    Returns:
        The highest minimum R2 value and the optimized hyperparameters.
    &#34;&#34;&#34;
    r2_threshs: np.ndarray = np.around(np.linspace(start=0.9, stop=0.99, num=num_params), decimals=2)
    thresh_fracs: np.ndarray = np.around(np.linspace(start=0.5, stop=0.9, num=num_params), decimals=1)
    sigma_thresh_fracs: np.ndarray = np.around(np.linspace(start=0.1, stop=0.2, num=num_params), decimals=1)

    odmr_sample: dict = {}
    for k, v in random.sample(sorted(measurements.items()), k=num_samples):
        odmr_sample[k] = v

    highest_min_r2: float = 0
    optimal_params: Tuple[float, float, float] = (0, 0, 0)

    for idx, (r2_thresh, thresh_frac, sigma_thresh_frac) in enumerate(
            product(r2_threshs, thresh_fracs, sigma_thresh_fracs)):
        odmr_sample = self.fit_raster_odmr(
            odmr_sample,
            r2_thresh=r2_thresh,
            thresh_frac=thresh_frac,
            sigma_thresh_frac=sigma_thresh_frac,
            min_thresh=0.01,
            progress_bar=False
        )

        r2s: np.ndarray = np.zeros(len(odmr_sample))
        for _idx, odmr in enumerate(odmr_sample.values()):
            r2s[_idx] = odmr.fit_model.rsquared
        min_r2: float = np.min(r2s)

        if highest_min_r2 &lt; min_r2:
            highest_min_r2 = min_r2
            optimal_params = (r2_thresh, thresh_frac, sigma_thresh_frac)

    return highest_min_r2, optimal_params</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators"><code class="flex name class">
<span>class <span class="ident">FitMethodsAndEstimators</span></span>
</code></dt>
<dd>
<div class="desc"><p>Class for storing fit methods and estimators.
Fit methods are stored as tuples of (method, estimator)
where method is the name of the fit method and estimator is the name of the estimator.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FitMethodsAndEstimators:
    &#34;&#34;&#34;
        Class for storing fit methods and estimators.
        Fit methods are stored as tuples of (method, estimator)
        where method is the name of the fit method and estimator is the name of the estimator.
    &#34;&#34;&#34;
    # Fit methods with corresponding estimators
    antibunching: tuple = (&#34;antibunching&#34;, &#34;dip&#34;)
    hyperbolicsaturation: tuple = (&#34;hyperbolicsaturation&#34;, &#34;generic&#34;)
    lorentzian: tuple = (&#34;lorentzian&#34;, &#34;dip&#34;)
    lorentziandouble: tuple = (&#34;lorentziandouble&#34;, &#34;dip&#34;)
    sineexponentialdecay: tuple = (&#34;sineexponentialdecay&#34;, &#34;generic&#34;)
    decayexponential: tuple = (&#34;decayexponential&#34;, &#34;generic&#34;)
    gaussian: tuple = (&#34;gaussian&#34;, &#34;dip&#34;)
    gaussiandouble: tuple = (&#34;gaussiandouble&#34;, &#34;dip&#34;)
    gaussianlinearoffset: tuple = (&#34;gaussianlinearoffset&#34;, &#34;dip&#34;)
    lorentziantriple: tuple = (&#34;lorentziantriple&#34;, &#34;dip&#34;)
    biexponential: tuple = (&#34;biexponential&#34;, &#34;generic&#34;)
    decayexponentialstretched: tuple = (&#34;decayexponentialstretched&#34;, &#34;generic&#34;)
    linear: tuple = (&#34;linear&#34;, &#34;generic&#34;)
    sine: tuple = (&#34;sine&#34;, &#34;generic&#34;)
    sinedouble: tuple = (&#34;sinedouble&#34;, &#34;generic&#34;)
    sinedoublewithexpdecay: tuple = (&#34;sinedoublewithexpdecay&#34;, &#34;generic&#34;)
    sinedoublewithtwoexpdecay: tuple = (&#34;sinedoublewithtwoexpdecay&#34;, &#34;generic&#34;)
    sinestretchedexponentialdecay: tuple = (&#34;sinestretchedexponentialdecay&#34;, &#34;generic&#34;)
    sinetriple: tuple = (&#34;sinetriple&#34;, &#34;generic&#34;)
    sinetriplewithexpdecay: tuple = (&#34;sinetriplewithexpdecay&#34;, &#34;generic&#34;)
    sinetriplewiththreeexpdecay: tuple = (&#34;sinetriplewiththreeexpdecay&#34;, &#34;generic&#34;)
    twoDgaussian: tuple = (&#34;twoDgaussian&#34;, &#34;generic&#34;)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.antibunching"><code class="name">var <span class="ident">antibunching</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.biexponential"><code class="name">var <span class="ident">biexponential</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.decayexponential"><code class="name">var <span class="ident">decayexponential</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.decayexponentialstretched"><code class="name">var <span class="ident">decayexponentialstretched</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.gaussian"><code class="name">var <span class="ident">gaussian</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.gaussiandouble"><code class="name">var <span class="ident">gaussiandouble</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.gaussianlinearoffset"><code class="name">var <span class="ident">gaussianlinearoffset</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.hyperbolicsaturation"><code class="name">var <span class="ident">hyperbolicsaturation</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.linear"><code class="name">var <span class="ident">linear</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.lorentzian"><code class="name">var <span class="ident">lorentzian</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.lorentziandouble"><code class="name">var <span class="ident">lorentziandouble</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.lorentziantriple"><code class="name">var <span class="ident">lorentziantriple</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sine"><code class="name">var <span class="ident">sine</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinedouble"><code class="name">var <span class="ident">sinedouble</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinedoublewithexpdecay"><code class="name">var <span class="ident">sinedoublewithexpdecay</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinedoublewithtwoexpdecay"><code class="name">var <span class="ident">sinedoublewithtwoexpdecay</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sineexponentialdecay"><code class="name">var <span class="ident">sineexponentialdecay</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinestretchedexponentialdecay"><code class="name">var <span class="ident">sinestretchedexponentialdecay</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinetriple"><code class="name">var <span class="ident">sinetriple</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinetriplewithexpdecay"><code class="name">var <span class="ident">sinetriplewithexpdecay</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinetriplewiththreeexpdecay"><code class="name">var <span class="ident">sinetriplewiththreeexpdecay</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.twoDgaussian"><code class="name">var <span class="ident">twoDgaussian</span> : tuple</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="qudi_hira_analysis" href="index.html">qudi_hira_analysis</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic">AnalysisLogic</a></code></h4>
<ul class="">
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyse_mean" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.analyse_mean">analyse_mean</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyse_mean_norm" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.analyse_mean_norm">analyse_mean_norm</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyse_mean_reference" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.analyse_mean_reference">analyse_mean_reference</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyze_mean" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.analyze_mean">analyze_mean</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyze_mean_norm" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.analyze_mean_norm">analyze_mean_norm</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.analyze_mean_reference" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.analyze_mean_reference">analyze_mean_reference</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.average_raster_odmr_pixels" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.average_raster_odmr_pixels">average_raster_odmr_pixels</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.fit" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.fit">fit</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.fit_function" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.fit_function">fit_function</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.fit_raster_odmr" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.fit_raster_odmr">fit_raster_odmr</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.get_all_fits" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.get_all_fits">get_all_fits</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.AnalysisLogic.optimize_raster_odmr_params" href="#qudi_hira_analysis.analysis_logic.AnalysisLogic.optimize_raster_odmr_params">optimize_raster_odmr_params</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators">FitMethodsAndEstimators</a></code></h4>
<ul class="">
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.antibunching" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.antibunching">antibunching</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.biexponential" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.biexponential">biexponential</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.decayexponential" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.decayexponential">decayexponential</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.decayexponentialstretched" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.decayexponentialstretched">decayexponentialstretched</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.gaussian" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.gaussian">gaussian</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.gaussiandouble" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.gaussiandouble">gaussiandouble</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.gaussianlinearoffset" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.gaussianlinearoffset">gaussianlinearoffset</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.hyperbolicsaturation" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.hyperbolicsaturation">hyperbolicsaturation</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.linear" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.linear">linear</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.lorentzian" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.lorentzian">lorentzian</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.lorentziandouble" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.lorentziandouble">lorentziandouble</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.lorentziantriple" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.lorentziantriple">lorentziantriple</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sine" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sine">sine</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinedouble" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinedouble">sinedouble</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinedoublewithexpdecay" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinedoublewithexpdecay">sinedoublewithexpdecay</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinedoublewithtwoexpdecay" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinedoublewithtwoexpdecay">sinedoublewithtwoexpdecay</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sineexponentialdecay" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sineexponentialdecay">sineexponentialdecay</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinestretchedexponentialdecay" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinestretchedexponentialdecay">sinestretchedexponentialdecay</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinetriple" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinetriple">sinetriple</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinetriplewithexpdecay" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinetriplewithexpdecay">sinetriplewithexpdecay</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinetriplewiththreeexpdecay" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.sinetriplewiththreeexpdecay">sinetriplewiththreeexpdecay</a></code></li>
<li><code><a title="qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.twoDgaussian" href="#qudi_hira_analysis.analysis_logic.FitMethodsAndEstimators.twoDgaussian">twoDgaussian</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>